{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6f4206-e505-43f8-9eee-cef63d11ddd8",
   "metadata": {},
   "source": [
    "# Collect and upload precomputed skeletons with ccf transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963a91bc-2936-499e-ab7f-4414ab17b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535122a9-488b-4cf6-a5b4-643128dd382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f3f00d-5913-4e53-83b5-15c3e4185fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudvolume\n",
    "import caveclient\n",
    "import pcg_skel\n",
    "from meshparty import skeleton\n",
    "\n",
    "client = caveclient.CAVEclient('minnie65_public')\n",
    "client.materialize.version = 1078\n",
    "cv_minnie = cloudvolume.CloudVolume(client.info.segmentation_source(), use_https=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4f7a8a-0ebc-41ac-995d-4d347ada8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import precomputed_utils as pcu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167dc48-07e4-45d8-83c7-5da956b5b840",
   "metadata": {},
   "source": [
    "## Create cloudvolume directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cea507d-3145-4207-9546-0ad797d8b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = cloudvolume.CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    # raw, png, jpeg, compressed_segmentation, fpzip, kempressed, zfpc, compresso, crackle\n",
    "    encoding        = 'raw', \n",
    "    resolution      = [1000, 1000, 1000], # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = [0, 0, 0], # x,y,z offset in voxels from the origin\n",
    "    mesh            = 'mesh',\n",
    "    skeletons        = 'skeleton',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 512, 512, 512 ], # units are voxels\n",
    "    volume_size     = [13200, 8000, 11400 ], # e.g. a cubic millimeter dataset\n",
    ")\n",
    "info['segment_properties']='segment_properties'\n",
    "\n",
    "cv = cloudvolume.CloudVolume(\"precomputed://gs://allen_neuroglancer_ccf/em_minnie65_v661_v2\", mip=0, info=info, compress=False)\n",
    "cv.commit_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b305a-0253-41cb-afeb-dd8fbad601d3",
   "metadata": {},
   "source": [
    "## Create the skeleton properties\n",
    "https://github.com/google/neuroglancer/blob/master/src/datasource/precomputed/skeletons.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c3a33ff-7868-4301-a0c7-cad57cbcf861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change cloudvolume properties \n",
    "sk_info = cv.skeleton.meta.default_info()\n",
    "\n",
    "\n",
    "sk_info['transform'] = [-0.20923994, -0.01442708, -1.15535762, 9296.273617,\n",
    "                        0.48709059, 0.9850834, -0.16600506, 230.5823285366,\n",
    "                        0.72729732, -0.66388746, -0.22121276, 8605.414249918707]\n",
    "\n",
    "\n",
    "sk_info['vertex_attributes'] = [\n",
    "    { 'id': 'radius',\n",
    "        'data_type': 'float32',\n",
    "        'num_components': 1\n",
    "    },\n",
    "    {\n",
    "        'id': 'compartment',\n",
    "        'data_type': 'float32',\n",
    "        'num_components': 1\n",
    "    },\n",
    "    {\n",
    "        'id': 'presyn_counts',\n",
    "        'data_type': 'float32',\n",
    "        'num_components': 1\n",
    "    },\n",
    "    {\n",
    "        'id': 'postsyn_counts',\n",
    "        'data_type': 'float32',\n",
    "        'num_components': 1\n",
    "    },\n",
    "    {\n",
    "        'id': 'presyn_size',\n",
    "        'data_type': 'float32',\n",
    "        'num_components': 1\n",
    "    },\n",
    "    {\n",
    "        'id': 'postsyn_size',\n",
    "        'data_type': 'float32',\n",
    "        'num_components': 1\n",
    "    }\n",
    "]\n",
    "cv.skeleton.meta.info = sk_info\n",
    "cv.skeleton.meta.commit_info()\n",
    "cv.skeleton.meta.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d5008-8d90-456a-9136-47a07eed4fb9",
   "metadata": {},
   "source": [
    "## Generate skeletons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547d5d1-8a5a-4f51-9b0c-52aa46d25d82",
   "metadata": {},
   "source": [
    "### query the cells with axon extension in v661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ef8786-e1be-43a7-8b86-84ebe0e961f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Table Owner Notice on proofreading_status_public_release: NOTE: this table is deprecated and no longer receiving updates; please use 'proofreading_status_and_strategy' which is available in datastack version >= 1078 (datastack = minnie65_public or minnie65_phase3_v1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272 cells with proofread axons and dendrites in v661\n",
      "325 cells with axon extended in v661\n"
     ]
    }
   ],
   "source": [
    "prf_df = client.materialize.tables.proofreading_status_public_release().query(materialization_version=661)\n",
    "\n",
    "print(f\"{len(prf_df)} cells with proofread axons and dendrites in v661\")\n",
    "\n",
    "axon_extended = prf_df.query(\"(status_axon=='extended') & ( (status_dendrite=='clean') | (status_dendrite=='extended') )\").pt_root_id.unique()\n",
    "\n",
    "print(f\"{len(axon_extended)} cells with axon extended in v661\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fecf3b9-18fa-4b05-ad31-1714a8e362da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `client.materialize.tables` interface is experimental and might experience breaking changes before the feature is stabilized.\n",
      "The `client.materialize.tables` interface is experimental and might experience breaking changes before the feature is stabilized.\n"
     ]
    }
   ],
   "source": [
    "# Get cell type information\n",
    "nuc_df = client.materialize.tables.nucleus_detection_v0(pt_root_id=axon_extended).query(\n",
    "    select_columns= ['id','pt_root_id','pt_position'],\n",
    "    desired_resolution=[4,4,40],\n",
    "    materialization_version=661,)\n",
    "\n",
    "ct_df = client.materialize.tables.aibs_metamodel_celltypes_v661(target_id=nuc_df.id.values).query(\n",
    "    select_columns={'nucleus_detection_v0': ['id'],\n",
    "                    'aibs_metamodel_celltypes_v661': ['cell_type']},\n",
    "    desired_resolution=[4,4,40],\n",
    "    materialization_version=1078,)\n",
    "\n",
    "# Brain area information (only added in v1078)\n",
    "area_df = client.materialize.tables.nucleus_functional_area_assignment(target_id=nuc_df.id.values).query(\n",
    "    select_columns={'nucleus_detection_v0': ['id','pt_root_id'],\n",
    "                    'nucleus_functional_area_assignment': ['tag']},\n",
    "    desired_resolution=[4,4,40],\n",
    "    materialization_version=1078,)\n",
    "\n",
    "ct_df = pd.merge(nuc_df, ct_df, on='id', how='left', suffixes=['','_1078'])\n",
    "\n",
    "area_df = pd.merge(ct_df, area_df, on='id', how='left', suffixes=['','_1078'])\n",
    "\n",
    "area_df.drop_duplicates(subset='pt_root_id', keep=False, inplace=True)\n",
    "\n",
    "# remove nan values\n",
    "area_df.cell_type.fillna('none', inplace=True)\n",
    "area_df.tag.fillna('none', inplace=True)\n",
    "\n",
    "area_df.rename(columns={'tag': 'brain_area', 'id': 'nucleus_id'}, inplace=True)\n",
    "\n",
    "skel_seg_properties_df = area_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8b418-1132-479c-ae4d-9a5b26ab8a46",
   "metadata": {},
   "source": [
    "## Load .h5 meshwork and format as precomputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc46e8da-46a0-443b-a1ea-c9b717663dc8",
   "metadata": {},
   "source": [
    "### load meshwork specific packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e1e5c3-6790-4ead-93a3-9dfa11391d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skeleton_plot.skel_io as skel_io\n",
    "\n",
    "# path to the skeleton and meshwork .h5 files\n",
    "mesh_path = \"https://storage.googleapis.com/allen-minnie-phase3/minniephase3-emily-pcg-skeletons/minnie_all/v661/meshworks/\"\n",
    "\n",
    "def pull_mw_skel_colors(mw, basal_table, axon_table, apical_table):\n",
    "    ''' pulls the segment properties from meshwork anno and translates into skel index\n",
    "    basal node table used for general dendrite labels if no apical/basal differentiation\n",
    "    apical_table is optional \n",
    "    '''\n",
    "    node_labels = np.full(len(mw.skeleton.vertices), 0)\n",
    "    soma_node = mw.skeleton.root\n",
    "    \n",
    "    basal_nodes = mw.anno[basal_table].skel_index\n",
    "    node_labels[basal_nodes] = 3\n",
    "\n",
    "    node_labels[soma_node] = 1\n",
    "\n",
    "    axon_nodes = mw.anno[axon_table].skel_index\n",
    "\n",
    "    if apical_table is not None:\n",
    "        apical_nodes = mw.anno[apical_table].skel_index\n",
    "        node_labels[apical_nodes] = 4            \n",
    "    \n",
    "    node_labels[axon_nodes] = 2\n",
    "\n",
    "    if 0 in node_labels:\n",
    "        print(\"Warning: label annotations passed give labels that are shorter than total length of skeleton nodes to label. Unassigned nodes have been labeled 0. if using pull_compartment_colors, add an option for 0 in inskel_color_map such as skel_color_map={3: 'firebrick', 4: 'salmon', 2: 'steelblue', 1: 'olive', 0:'gray'}.\")\n",
    "\n",
    "    return node_labels\n",
    "\n",
    "def get_skeleton_features_from_emily_meshwork(mw, properties_dict):\n",
    "    # extract vertices, edges, radius, compartment labels\n",
    "    vertices = mw.skeleton.vertices\n",
    "    edges = mw.skeleton.edges\n",
    "\n",
    "    # transform vertices into ccf directly\n",
    "    # vertices_transform = np.apply_along_axis(pcu.ccf_vertex_transform, 1, vertices)\n",
    "    \n",
    "    # pulls the segment properties from meshwork anno and translates into skel index\n",
    "    r_df = mw.anno.segment_properties.df[['r_eff', 'mesh_ind_filt']].set_index('mesh_ind_filt')\n",
    "    radius = r_df.loc[mw.skeleton_indices.to_mesh_region_point].r_eff.values/1000\n",
    "    \n",
    "    # get compartment labels\n",
    "    compartment = pull_mw_skel_colors(mw, 'basal_mesh_labels', 'is_axon', 'apical_mesh_labels')\n",
    "\n",
    "    # update properties\n",
    "    properties_dict['compartment'] = compartment\n",
    "    properties_dict['vertices'] = vertices\n",
    "    # properties_dict['vertices_transform'] = vertices_transform\n",
    "    properties_dict['edges'] = edges\n",
    "    properties_dict['radius'] = radius\n",
    "\n",
    "    return properties_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c9b1d4-1bd2-4734-b593-8cf3d208bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa53ee54-cc95-4563-a67e-74fead1098e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69fe6a1d37143868d6b7766e2e4fffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864691136452054015 292669 [188048 123136  20983]\n"
     ]
    }
   ],
   "source": [
    "seg_props_list = []\n",
    "\n",
    "for ii in trange(len(skel_seg_properties_df)):\n",
    "    segment_id, nucleus_id, nucleus_position = skel_seg_properties_df.iloc[ii].loc[['pt_root_id','nucleus_id','pt_position']]\n",
    "    \n",
    "    print(segment_id, nucleus_id, nucleus_position)\n",
    "\n",
    "    # get meshwork\n",
    "    mw = skel_io.load_mw(mesh_path, f\"{segment_id}_{nucleus_id}.h5\")\n",
    "    \n",
    "    # initialize skeleton_properties dict\n",
    "    skeleton_properties = {}\n",
    "    \n",
    "    # Add properties\n",
    "    skeleton_properties = get_skeleton_features_from_emily_meshwork(mw, skeleton_properties)\n",
    "    \n",
    "    # Add synapse info\n",
    "    skeleton_properties = pcu.get_postsynapse_features_from_meshwork(mw, skeleton_properties)\n",
    "    skeleton_properties = pcu.get_presynapse_features_from_meshwork(mw, skeleton_properties)\n",
    "    \n",
    "    # write precomputed skeleton to disk\n",
    "    sk_cv = cloudvolume.Skeleton(skeleton_properties['vertices'], \n",
    "                                 # skeleton_properties['vertices_transform'],\n",
    "                                 skeleton_properties['edges'], \n",
    "                                 skeleton_properties['radius'],\n",
    "                                 None, \n",
    "                                 segid= segment_id,\n",
    "                                 extra_attributes = sk_info['vertex_attributes'])\n",
    "    sk_cv.compartment = skeleton_properties['compartment'].astype(np.float32)\n",
    "    sk_cv.presyn_counts = skeleton_properties['presyn_counts'].astype(np.float32)\n",
    "    sk_cv.postsyn_counts = skeleton_properties['postsyn_counts'].astype(np.float32)\n",
    "    sk_cv.presyn_size = skeleton_properties['presyn_size'].astype(np.float32)\n",
    "    sk_cv.postsyn_size = skeleton_properties['postsyn_size'].astype(np.float32)\n",
    "    \n",
    "    cv.skeleton.upload(sk_cv)\n",
    "\n",
    "    # ## To load previously generated precomputed skeleton\n",
    "    # sk_cv = cv.skeleton.get(segment_id) #load an example skeleton\n",
    "    # mw = skeleton.Skeleton(sk_cv.vertices, \n",
    "    #                        sk_cv.edges, \n",
    "    #                        vertex_properties={'radius': sk_cv.radius,\n",
    "    #                                           'compartment': sk_cv.compartment}, \n",
    "    #                        root = len(sk_cv.edges), # the final edge is root\n",
    "    #                        remove_zero_length_edges = False)\n",
    "    \n",
    "    # segment info properties: axon pathlength, dendrite pathlength, n input synapses, n output synapses\n",
    "    axon_inds = sk_cv.compartment==2\n",
    "    dendrite_inds = sk_cv.compartment!=2\n",
    "    \n",
    "    mw_axon = mw.skeleton.apply_mask(axon_inds)\n",
    "    axon_pathlength = mw_axon.path_length() / 1000\n",
    "    \n",
    "    mw_dendrite = mw.skeleton.apply_mask(dendrite_inds)\n",
    "    dendrite_pathlength = mw_dendrite.path_length() / 1000\n",
    "\n",
    "    seg_props_list.append({'pt_root_id': segment_id,\n",
    "                           'axon_length_um': axon_pathlength,\n",
    "                           'dendrite_length_um': dendrite_pathlength,\n",
    "                           'input_synapse_count': sk_cv.postsyn_counts.sum(),\n",
    "                           'output_synapse_count': sk_cv.presyn_counts.sum(),\n",
    "                          })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f2daf-ebe5-4929-a939-1d8ec789927f",
   "metadata": {},
   "source": [
    "### curate the skeleton segment properties table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26d2c74d-29c3-4560-af56-ca7112a17196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pt_root_id': 864691136452054015,\n",
       "  'axon_length_um': 26758.324,\n",
       "  'dendrite_length_um': 5176.373,\n",
       "  'input_synapse_count': 13541.0,\n",
       "  'output_synapse_count': 5184.0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_props_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89d5328e-f241-4af7-bfda-84aac4e26c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_seg_properties_df = area_df.copy()\n",
    "skel_seg_properties_df.drop(columns=['pt_position','pt_root_id_1078'], inplace=True)\n",
    "\n",
    "# format nucleus id as string\n",
    "skel_seg_properties_df['nucleus_id'] = skel_seg_properties_df['nucleus_id'].apply(lambda x: 'nuc:' + str(x))\n",
    "\n",
    "# add the iterated properties\n",
    "input_output_properties = pd.DataFrame(seg_props_list)\n",
    "skel_seg_properties_df = pd.merge(skel_seg_properties_df, input_output_properties,\n",
    "                                  on='pt_root_id',\n",
    "                                  how='left')\n",
    "\n",
    "skel_seg_properties_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671738b-c08c-4a31-96a8-42726c3f8a92",
   "metadata": {},
   "source": [
    "### make skeleton properties with nglui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be8850d1-99ec-4018-80c6-842bf2324750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nglui.segmentprops import SegmentProperties\n",
    "\n",
    "seg_prop = SegmentProperties.from_dataframe(\n",
    "    skel_seg_properties_df,\n",
    "    id_col='pt_root_id',\n",
    "    label_col='nucleus_id',\n",
    "    number_cols=['axon_length_um', 'dendrite_length_um', 'input_synapse_count', 'output_synapse_count'],\n",
    "    tag_value_cols=['cell_type','brain_area']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fb8a7b5-327d-4e44-b3b8-184bbf26322b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cloudfiles import CloudFiles\n",
    "\n",
    "cf = CloudFiles(cv.cloudpath)\n",
    "filename = \"segment_properties/info\"\n",
    "cf.put_json(filename, seg_prop.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "368ed7eb-8e3b-4c64-96b8-467e660b5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save locally\n",
    "import json\n",
    "\n",
    "with open('em_minnie65_v661_v2/segment_properties/info', 'w') as f:\n",
    "    json.dump(seg_prop.to_dict(), f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cc205-a0bb-4f56-aead-0dd8cb10fe8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microns2024",
   "language": "python",
   "name": "microns2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
